<!DOCTYPE HTML>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-97H2VHVN0S"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-97H2VHVN0S');
</script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Junhyuk So</title>

    <meta name="author" content="Junhyuk So">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Junhyuk So
                </p>
                <p>
                  I am a Ph.D. candidate at <a href="https://postech.ac.kr/eng/index.do">POSTECH</a> CSE, advised by <a href="https://scholar.google.com/citations?user=pBr1GV4AAAAJ&hl=en">Prof. Eunhyeok Park</a>.<BR> I work on building efficient machine learning algorithms with real world applications - vision, language, audio and robotics.
 
                  <p></p>
                   
                  I am a member of both <a href="https://sites.google.com/view/eh-p">Efficient Computing Lab</a> and the <a href="https://ml.postech.ac.kr/">Machine Learning Lab</a>.
                  Publications from our groups are available <a href="https://sites.google.com/view/eh-p">here (ECo)</a> and <a href="https://ml.postech.ac.kr/#publication">here (ML)</a>.
                   
                  <p></p>
                  
                  <i>Education.</i> I started my Ph.D. in <a href="https://cse.postech.ac.kr/csepostech/index.do#none">Computer Science and Engineering</a> at <a href="https://postech.ac.kr/eng/index.do">POSTECH</a> in 2022. Previously, I received my B.S. in <a href="https://engineering.uos.ac.kr/engineering/depart/ecehp/main.do">Electrical and Computer Engineering</a> from the <a href="https://www.uos.ac.kr/eng/web/main">University of Seoul</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:junhyukso@postech.ac.kr">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_Junhyuk_So.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=uYE7vtEAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/junhyuk-so-0a91631ab">LinkedIn</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/junhyuk.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/junhyuk.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am primarily interested in enhancing efficiency of machine learning algorithms, especially for generative models. Most of my work involves designing efficient inference algorithms for vision generation. I am also deeply interested in general ML topics, such as optimization or numerical methods.
              
              </p>
                <i>
                  Keyword : [Diffusion], [LLM/VLM],[Efficient ML],  [Quantization], [Parallelization] [Multimodal]
                </i>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <!-- ICCV'25 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/gsd_fig.PNG" alt="so2025gsd" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://junhyukso.github.io/404" id="so2025gsd">
            <papertitle>Grouped Speculative Decoding for Autoregressive Image Generation
            </papertitle>
            </a>
            <br>
            <strong>Junhyuk So</strong>,
            <a href="https://scholar.google.com/citations?user=tWfqGIMAAAAJ&hl=ko">Juncheol Shin</a>,             
            <a href="https://www.linkedin.com/in/hyunho-kook/">Hyunho Kook</a>
            and <a href="https://scholar.google.com/citations?user=pBr1GV4AAAAJ&hl=en">Eunhyeok Park</a>.
          
            <br>
            <em>ICCV</em>, 2025
            <br>
            <a href="https://junhyukso.github.io/404">arXiv</a> /
            <a href="https://junhyukso.github.io/404">Code</a> 
            <p></p>

            <i>
              Keyword :  [VLM],[Efficient ML], [Parallelization],[Speculative Decoding]
            </i>

          </td>
         </tr>


        <!-- CVPR'25 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/pcm_fig.PNG" alt="so2025pcm" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2503.19731" id="so2025pcm">
            <papertitle>PCM : Picard Consistency Model for Fast Parallel Sampling of Diffusion Models
            </papertitle>
            </a>
            <br>
            <strong>Junhyuk So</strong>,
            <a href="https://jiwoongshin.notion.site/">Jiwoong Shin</a>,             
            <a href="https://www.linkedin.com/in/chaeyeon-jang-33a566276/">Chaeyeon Jang</a>
            and <a href="https://scholar.google.com/citations?user=pBr1GV4AAAAJ&hl=en">Eunhyeok Park</a>.
          
            <br>
            <em>CVPR</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2503.19731">Paper</a> /
            <a href="https://arxiv.org/abs/2503.19731">arXiv</a> /
            <a href="https://arxiv.org/abs/2503.19731">Code</a> 
            <p></p>

            <i>
              Keyword :  [Diffusion],[Efficient ML], [Parallelization]
            </i>

          </td>
         </tr>


        <!-- ECCV'24 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/frdiff_fig.PNG" alt="so2024frdiff" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2312.03517" id="so2024frdiff">
            <papertitle>FRDiff : Feature Reuse for Universal Training-free Acceleration of Diffusion Models
            </papertitle>
            </a>
            <br>
            <strong>Junhyuk So*</strong>,
            <a href="https://scholar.google.com/citations?user=TbzDLMUAAAAJ">Jungwon Lee*</a>
            and <a href="https://scholar.google.com/citations?user=pBr1GV4AAAAJ&hl=en">Eunhyeok Park</a>.
          
            <br>
            <em>ECCV</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2312.03517">Paper</a> /
            <a href="https://arxiv.org/abs/2312.03517">arXiv</a> /
            <a href="https://jungwon-lee.github.io/Project_FRDiff/">Page</a> /
            <a href="https://github.com/Jungwon-Lee/FRDiff">Code</a>  /
            <a href="https://colab.research.google.com/drive/1nG15sCcIS-XaZKDvGugBvg4eKF3qftoA#scrollTo=zvA_neljsaaU">Colab</a> 
            <p></p>

            <i>
              Keyword :  [Diffusion],[Efficient ML], [Caching]
            </i>

          </td>
         </tr>


        <!-- NIPS'23 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/tdq_fig.PNG" alt="so2023tdq" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2306.02316" id="so2023tdq">
            <papertitle>Temporal Dynamic Quantizatin for Diffusion Models
            </papertitle>
            </a>
            <br>
            <strong>Junhyuk So*</strong>,
            <a href="https://scholar.google.com/citations?user=TbzDLMUAAAAJ">Jungwon Lee*</a>,
            <a href="https://scholar.google.com/citations?user=a4e-yE4AAAAJ">Daehyun Ahn</a>,
            <a href="https://scholar.google.co.kr/citations?user=pX2macYAAAAJ">Hyungjun Kim</a>
            and <a href="https://scholar.google.com/citations?user=pBr1GV4AAAAJ&hl=en">Eunhyeok Park</a>.
          
            <br>
            <em>NeurIPS</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2306.02316">Paper</a> /
            <a href="https://arxiv.org/abs/2306.02316">arXiv</a> /
            <a href="https://arxiv.org/abs/2306.02316">Code</a> 
            <p></p>

            <i>
              Keyword :  [Diffusion],[Efficient ML], [Quantization]
            </i>

          </td>
         </tr>


                  
        <!-- NIPS'23 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/m2mix_fig.PNG" alt="oh2023m2mix" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2203.03897" id="oh2023m2mix">
            <papertitle>Geodesic Multi-Modal Mixup for Robust Fine-Tuning
            </papertitle>
            </a>
            <br>
            <a href="https://changdaeoh.github.io/">Changdae Oh*</a>,
            <strong>Junhyuk So*</strong>,
            <a href="https://scholar.google.com/citations?user=55yqBlMAAAAJ">Hoyoon Byun</a>,
            <a href="https://scholar.google.com/citations?user=i-BJGx4AAAAJ">YongTaek Lim</a>,
            <a href="https://scholar.google.com/citations?hl=ko&user=52NtRk8AAAAJ">Minchul Shin</a>,
            <a href="https://scholar.google.com/citations?user=A-E3uEMAAAAJ">Jong-June Jeon</a>
            and <a href="https://scholar.google.com/citations?user=HWxRii4AAAAJ">Kyungwoo Song</a>.
          
            <br>
            <em>NeurIPS</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2203.03897">Paper</a> /
            <a href="https://arxiv.org/abs/2203.03897">arXiv</a> /
            <a href="https://github.com/changdaeoh/multimodal-mixup">Code</a> 
            <p></p>

            <i>
              Keyword :  [Multimodal],[Mix-Up]
            </i>

          </td>
         </tr>
        <!-- CVPR'23 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/nipq_fig.PNG" alt="shin2023nipq" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2206.00820" id="shin2023nipq">
            <papertitle>NIPQ: Noise Proxy-Based Integrated Pseudo-Quantization
            </papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?user=tWfqGIMAAAAJ&hl=ko">Juncheol Shin*</a>,           
            <strong>Junhyuk So*</strong>,
            <a href="https://www.linkedin.com/in/sein-park/">Sein Park</a>,
            <a href="https://openreview.net/profile?id=~Seungyeop_Kang1">Seungyeop Kang</a>,
            <a href="https://scholar.google.com/citations?user=__waCuYAAAAJ">Sungjoo Yoo</a>,
            and <a href="https://scholar.google.com/citations?user=pBr1GV4AAAAJ&hl=en">Eunhyeok Park</a>.
          
            <br>
            <em>CVPR</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2206.00820">Paper</a> /
            <a href="https://arxiv.org/abs/2206.00820">arXiv</a> /
            <a href="https://github.com/ECoLab-POSTECH/NIPQ">Code</a> 
            <p></p>

            <i>
              Keyword :  [Efficient ML],[Quantization]
            </i>

          </td>
         </tr>

        <!-- IEEE Access'23 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/dmm_fig.PNG" alt="so2023dmm" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/document/10154052/" id="so2023dmm">
            <papertitle>Robust Contrastive Learning With Dynamic Mixed Margin
            </papertitle>
            </a>
            <br>
            <strong>Junhyuk So*</strong>,
            <a href="https://scholar.google.com/citations?user=i-BJGx4AAAAJ">YongTaek Lim*</a>,
            <a href="https://www.linkedin.com/in/yewon-kim-5361b5252">Yewon Kim*</a>,
            <a href="https://changdaeoh.github.io/">Changdae Oh</a>,
            and <a href="https://scholar.google.com/citations?user=HWxRii4AAAAJ">Kyungwoo Song</a>.
          
            <br>
            <em>IEEE Access</em>, 2023
            <br>
            <a href="https://ieeexplore.ieee.org/document/10154052/">Paper</a> 
            <p></p>

            <i>
              Keyword :  [Multimodal],[Mix-Up]
            </i>

          </td>
         </tr>

        <!-- KDD'22 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/farcon_fig.PNG" alt="oh2022farcon" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2206.08743" id="oh2022farcon">
            <papertitle>Learning Fair Representation via Distributional Contrastive Disentanglement
            </papertitle>
            </a>
            <br>
            <a href="https://changdaeoh.github.io/">Changdae Oh</a>,
            <a href="https://scholar.google.com/citations?user=KtU2jNsAAAAJ">Heeji Won</a>,
            <strong>Junhyuk So</strong>,
            <a href="https://scholar.google.com/citations?user=0Qd9oTcAAAAJ">Taero Kim</a>,
            <a href="https://www.linkedin.com/in/yewon-kim-5361b5252">Yewon Kim</a>,
            <a href="https://scholar.google.com/citations?user=0pzb3WAAAAAJ">Hosik Choi</a>,
            and <a href="https://scholar.google.com/citations?user=HWxRii4AAAAJ">Kyungwoo Song</a>.
          
            <br>
            <em>KDD</em>, 2022
            <br>
            <a href="https://arxiv.org/abs/2206.08743">Paper</a> /
            <a href="https://arxiv.org/abs/2206.08743">arXiv</a> /
            <a href="https://github.com/changdaeoh/FarconVAE">Code</a> 
            <p></p>

              <i>
              Keyword :  [VAE], [Fairness]
            </i>

          </td>
         </tr>


        <!-- ESWEEK'21 accepted -->
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/spie_fig.jpg" alt="oh2021spie" width="160" >
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://dl.acm.org/doi/abs/10.1145/3477008" id="hoh2021spie">
            <papertitle>Exploiting Activation Sparsity for Fast CNN Inference on Mobile GPUs
            </papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?hl=ko&user=PYjQqaAAAAAJ">Chanyoung Oh*</a>,
            <strong>Junhyuk So*</strong>,
            <a href="https://scholar.google.com/citations?user=_M3MvZUAAAAJ">Sumin Kim*</a>
            and <a href="https://scholar.google.com/citations?user=uaZINRwAAAAJ">Youngmin Yi</a>.
          
            <br>
            <em>ESWeek(CODES+ISSS) </em> and <em> ACM TECS (journal track)</em>, 2021
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3477008">Paper</a> 
            <p></p>

            <i>
              Keyword :  [Efficient ML], [Pruning], [GPGPU]
            </i>
          </td>

         </tr>


         <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
          <tr>
            <td>
              <h2>Miscellanea</h2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <ul>
  <li> Academic Services : </li>
  <ul>
    <li> Reviewer : <a href="https://neurips.cc">NeurIPS</a> 24-25, <a href="https://cvpr.thecvf.com/">CVPR</a> 24-25, <a href="https://iclr.cc">ICLR</a> 25, <a href="https://aaai.org">AAAI</a> 25, <a href="https://wacv.thecvf.com/">WACV</a> 26</li> </li> 
  </ul>
   
  <li> Talks : </li>
  <ul>
    <li>Recent Topics on Image generation Acceleration @ Squeezebits. 25.06.30</li>
  </ul>
  <li> Teaching : </li>
  <ul>
    <li>Instructor : Introduction to Artifical Intelligence (CSED105)</li>
    <li>Instructor : Implementation and Acceleration of machine learning (AIGS510-01)</li>
  </ul>
  <ul>

          </tbody></table>

        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template borrowed from Jon Barron
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
